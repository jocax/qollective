# Constraint Enforcer MCP Server Configuration
# All values can be overridden by environment variables with CONSTRAINT_ENFORCER_ prefix
# Example: CONSTRAINT_ENFORCER_NATS_URL=nats://production:4222

[service]
name = "constraint-enforcer"
version = "0.1.0"
description = "TaleTrail Constraint Enforcer MCP Server - Enforces vocabulary and theme constraints"

# LLM Configuration
# Base URL for LLM API endpoint (compatible with OpenAI API format)
[llm]
type = "google"
url = "https://generativelanguage.googleapis.com"
default_model = "gemini-2.0-flash-lite"
use_default_model_fallback = true
timeout_secs = 180
max_tokens = 4096
temperature = 0.7
system_prompt_style = "chatml"

# Language-specific LLM models
[llm.models]
en = "gemini-2.0-flash-lite"
de = "gemini-2.0-flash-lite"

[nats]
url = "nats://localhost:5222"
subject = "mcp.constraint.enforce"
queue_group = "constraint-enforcer"

[nats.auth]
# NKey authentication (replaces mTLS client certificates)
nkey_file = "../nkeys/constraint-enforcer.nk"

[nats.tls]
# TLS for encryption (no client cert needed with NKey auth)
ca_cert = "../certs/ca.pem"

[constraints]
vocabulary_check_enabled = true
theme_consistency_enabled = true
required_elements_check_enabled = true
vocabulary_levels = ["basic", "intermediate", "advanced"]

# English vocabulary lists organized by complexity level
[vocabulary.english.basic]
words = [
    "the", "and", "run", "play", "friend", "happy", "cat", "dog",
    "sun", "moon", "star", "tree", "house", "water", "food", "big",
    "small", "red", "blue", "green", "fast", "slow", "up", "down"
]

[vocabulary.english.intermediate]
words = [
    "adventure", "explore", "discover", "investigate", "journey",
    "treasure", "mystery", "island", "ocean", "forest", "mountain",
    "creature", "ancient", "hidden", "secret", "challenge", "quest",
    "brave", "courage", "danger", "rescue", "protect", "wisdom"
]

[vocabulary.english.advanced]
words = [
    "phenomenon", "consequence", "investigate", "comprehend", "perception",
    "expedition", "hypothesis", "observation", "biodiversity", "ecosystem",
    "fascinating", "extraordinary", "magnificent", "peculiar", "remarkable",
    "intricate", "elaborate", "sophisticated", "illuminate", "unveil"
]

# German vocabulary lists organized by complexity level
[vocabulary.german.basic]
words = [
    "der", "und", "laufen", "spielen", "Freund", "glücklich",
    "Katze", "Hund", "Sonne", "Mond", "Stern", "Baum", "Haus",
    "Wasser", "Essen", "groß", "klein", "rot", "blau", "grün"
]

[vocabulary.german.intermediate]
words = [
    "Abenteuer", "erforschen", "entdecken", "untersuchen",
    "Reise", "Schatz", "Geheimnis", "Insel", "Ozean", "Wald",
    "Berg", "Kreatur", "alt", "versteckt", "geheim", "Herausforderung",
    "Quest", "mutig", "Mut", "Gefahr", "Rettung", "schützen"
]

[vocabulary.german.advanced]
words = [
    "Phänomen", "Konsequenz", "untersuchen", "begreifen", "Wahrnehmung",
    "Expedition", "Hypothese", "Beobachtung", "Biodiversität", "Ökosystem",
    "faszinierend", "außergewöhnlich", "großartig", "eigenartig",
    "bemerkenswert", "kompliziert", "aufwendig", "ausgeklügelt"
]

# Theme consistency configuration
[themes]
min_consistency_score = 0.6

[themes.keywords.ocean]
keywords = ["ocean", "water", "sea", "wave", "fish", "coral", "dive", "submarine", "whale", "dolphin", "beach", "tide", "current", "deep", "reef"]

[themes.keywords.space]
keywords = ["space", "star", "planet", "rocket", "astronaut", "galaxy", "nebula", "comet", "asteroid", "orbit", "cosmos", "universe", "satellite", "moon", "mars"]

[themes.keywords.forest]
keywords = ["forest", "tree", "wood", "leaf", "animal", "deer", "bird", "mushroom", "stream", "clearing", "canopy", "wildlife", "nature", "hiking", "trail"]

[themes.keywords.adventure]
keywords = ["adventure", "explore", "journey", "quest", "discover", "treasure", "map", "expedition", "challenge", "mystery", "search", "find", "brave", "hero", "courage"]

[themes.keywords.science]
keywords = ["science", "experiment", "laboratory", "research", "discovery", "hypothesis", "theory", "observation", "analysis", "data", "evidence", "test", "investigate", "study", "learn"]

[themes.keywords.friendship]
keywords = ["friend", "friendship", "together", "help", "share", "care", "trust", "team", "cooperation", "kindness", "support", "companion", "loyal", "bond", "unity"]

# Required elements for different story types
[required_elements]
moral_keywords = ["learn", "lesson", "moral", "teach", "value", "friendship", "honesty", "kindness", "courage", "respect", "responsibility", "empathy", "trust", "fairness", "compassion"]
science_keywords = ["fact", "science", "discover", "research", "study", "experiment", "observe", "investigate", "analyze", "evidence", "hypothesis", "theory", "knowledge", "understanding", "explanation"]
educational_keywords = ["education", "knowledge", "understand", "explain", "learn", "teaching", "concept", "idea", "skill", "practice", "information", "explore", "question", "answer", "reason"]

# Hybrid validation configuration for required elements checking
[constraints.validation]
# Keyword-based matching threshold (0.0 to 1.0). If this percentage of keywords from the
# required element are found in content, the element is considered matched without LLM check.
keyword_match_threshold = 0.8

# Enable LLM semantic fallback when keyword matching fails to meet threshold
enable_llm_fallback = true

# Minimum keyword length to consider (filters out common words like "a", "or", "und")
min_keyword_length = 3

# Maximum content length (in characters) to send to LLM for semantic checking
# Content longer than this will be truncated to save API costs
max_llm_content_length = 2000

# Stopwords to filter out when extracting keywords (common words with low semantic value)
# English stopwords
stopwords_en = [
    "the", "a", "an", "and", "or", "but", "in", "on", "at", "to", "for",
    "of", "with", "by", "from", "up", "about", "into", "through", "during",
    "before", "after", "above", "below", "between", "under", "again", "further",
    "then", "once", "here", "there", "when", "where", "why", "how", "all", "both",
    "each", "few", "more", "most", "other", "some", "such", "no", "nor", "not",
    "only", "own", "same", "so", "than", "too", "very", "can", "will", "just"
]

# German stopwords
stopwords_de = [
    "der", "die", "das", "den", "dem", "des", "ein", "eine", "einer", "eines",
    "und", "oder", "aber", "in", "an", "auf", "zu", "für", "von", "mit", "bei",
    "aus", "nach", "über", "unter", "zwischen", "durch", "gegen", "ohne", "um",
    "vor", "hinter", "neben", "seit", "bis", "während", "wegen", "trotz", "statt",
    "als", "wenn", "ob", "weil", "dass", "damit", "also", "dann", "doch", "noch",
    "schon", "auch", "nur", "sehr", "mehr", "am", "im", "zum", "zur"
]

# LLM semantic checking prompt template (used when keyword matching is below threshold)
llm_semantic_prompt = """Does the following content convey or address the concept of '{element}'?

Content:
{content}

Answer with ONLY 'yes' or 'no' (no explanation needed)."""
