# Holodeck Coordinator Service Configuration

[service]
name = "holodeck-coordinator"
version = "0.1.0"

[llm]
# Primary LLM provider: "openai", "ollama", "anthropic", "perplexity"
provider = "ollama"

# Model name to use
model = "gemma2:2b"

# Optional: Custom API key (overrides .env file)
# api_key = "your_custom_key_here"

# Optional: Custom endpoint URL (for Ollama or custom providers)
# endpoint_url = "http://localhost:11434"

# Response parameters
temperature = 0.7
max_tokens = 2048
timeout_seconds = 30

[orchestration_ai]
# Orchestration-specific AI settings
response_time_target_ms = 100
service_coordination_timeout_ms = 5000
workflow_execution_timeout_ms = 30000
performance_optimization_enabled = true
health_monitoring_interval_ms = 1000
max_concurrent_orchestrations = 100
enable_advanced_workflow_management = true
enable_distributed_validation = true