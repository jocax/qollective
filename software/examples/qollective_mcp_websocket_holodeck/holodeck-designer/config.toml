# Holodeck Designer Service Configuration
# LLM-powered story generation and design for Star Trek holodeck experiences

[service]
name = "holodeck-designer"
version = "0.1.0"

[llm]
# LLM provider: "openai", "ollama", "anthropic", "perplexity"
provider = "ollama"

# Model selection for story generation
# Ollama: "gemma2:2b", "llama3.2:3b", "llama3.2:1b"
# OpenAI: "gpt-4", "gpt-3.5-turbo"
# Anthropic: "claude-3-haiku-20240307", "claude-3-sonnet-20240229"
# Perplexity: "llama-3.1-sonar-small-128k-online", "llama-3.1-sonar-large-128k-online"
model = "gemma2:2b"

# API key (optional - will use environment variables if not specified)
# api_key = "your-api-key-here"

# Custom endpoint URL (for ollama or custom deployments)
# endpoint_url = "http://localhost:11434"

# LLM generation parameters for story creation
temperature = 0.7          # Balanced creativity for story generation (0.0-1.0)  
max_tokens = 2048          # Optimized token limit for performance (reduced from 4096)
timeout_seconds = 8        # Realistic timeout for fast model responses (reduced from 45)

[story_design]
# Performance target: story generation should complete as fast as possible
story_generation_timeout_ms = 5000  # Realistic target for LLM calls (5 seconds)

# Story complexity level (1-10, higher = more intricate plots)
max_story_complexity = 8

# Enable integration with holodeck-character service for character consistency
enable_character_integration = true

# Enable AI-powered canon consistency checking
canon_consistency_check = true

# Creativity level for story enhancement (0.0-1.0)
creativity_level = 0.8