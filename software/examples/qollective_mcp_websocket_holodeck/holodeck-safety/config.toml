# Holodeck Safety Service Configuration

[service]
name = "holodeck-safety"
version = "0.1.0"

[llm]
# Primary LLM provider: "openai", "ollama", "anthropic", "perplexity"
provider = "ollama"

# Model name to use
model = "gemma2:2b"

# Optional: Custom API key (overrides .env file)
# api_key = "your_custom_key_here"

# Optional: Custom endpoint URL (for Ollama or custom providers)
# endpoint_url = "http://localhost:11434"

# Response parameters optimized for safety analysis
temperature = 0.3        # Low temperature for consistent, conservative safety analysis
max_tokens = 2500        # Medium token limit for detailed safety assessments
timeout_seconds = 30

[safety_ai]
# Safety-specific AI settings
response_time_target_ms = 300    # PRP requirement: < 300ms response time
analysis_depth = "comprehensive" # Level of analysis detail
risk_assessment_threshold = 0.7  # Threshold for flagging risks
compliance_strictness = "high"   # Compliance validation strictness
content_filtering_enabled = true # Enable content filtering
real_time_monitoring = true     # Enable real-time safety monitoring
automated_intervention = true   # Enable automated safety interventions

[safety_profiles]
# Safety profile configurations for different safety levels
training_max_risk = "none"
standard_max_risk = "low"
reduced_max_risk = "medium" 
disabled_max_risk = "high"

[compliance]
# Compliance validation settings
starfleet_regulations = true
federation_standards = true
cultural_sensitivity = true
educational_standards = true
privacy_protection = true